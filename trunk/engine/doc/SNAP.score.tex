\documentclass{amsart}
%\usepackage{amsmath, amsthm, amssymb}

% define the title
\author{Aviad Rozenhek}
\title{SNAP: How scores are computed}

\theoremstyle{definition}
\newtheorem*{sequence}{Definition: Sequence} 
\newtheorem*{database}{Definition: Database}
\newtheorem*{pcluster}{Definition: PCluster}
\newtheorem*{cluster}{Definition: Cluster}
\newtheorem*{score}{Definition}
\theoremstyle{remark}
\newtheorem* {loghyge}{Remark} 
\theoremstyle{definition}
\newtheorem*{exploss}{Definition}
\newtheorem* {hyge}{Definition} 
\theoremstyle{remark}
\newtheorem* {scoreremark}{Remark}
\newtheorem*{discweights}{Discrete pweight}
\newtheorem*{realweights}{Real pweight}
\newtheorem*{posweights}{Positional pweight}
\newtheorem*{genecounts}{Definition}
\newtheorem*{totalcounts}{Definition}

\begin{document}
% generates the title
\maketitle
% insert the table of contents
\tableofcontents

\section{Basic notation}
%\subsection{Basic notation}

This document describes how SeedSearcher scores motifs,
and consists mainly of definitions, which are mathematical in nature, but quite simple.

\begin{sequence} 
A \emph{sequence} $S$ is a finite vector of characters 
from an alphabet which we shall keep fixed.
The j-th coordinate $S_j$ of the sequence shall be called the j-th position. 
We shall identify $S$ with the set of all positions of $S$,
thus we can (ab)use notation like $S_j \in S$.
\end{sequence}

Usually we work with gene promotor sequences, where a position is a downstream offset.

\begin{database} 
An ordered set $G$ of sequences shall be called a \emph{database}. 
We shall think of $G$ as fixed, with cardinality $N$ = number of sequences.
Thus every sequence $S$ shall be denoted by $S^i \in G$ for some $i$.
\end{database}

Usually a database is a collection of named gene promoter sequences.
We are interested in scoring different ``motifs'' against the database.
We shall identify a motif with the set of positions
in the database, where the motif 'resides' (usually the starting position of the motif).
We shall calls these sets Clusters:

\begin{pcluster} 
An \emph{i-Position Cluster} $C^i$ is a set of positions, all belonging to the i-th sequence:
$C^i \subseteq S^i$. 
We shall denote by $\bar{C^i} = \{ C^i : C^i \subseteq S^i \}$ 
the set of all i-Position Clusters.
\end{pcluster}

\begin{cluster} 
An ordered set (or vector) $C$ of position clusters shall be called a \emph{Cluster}.
$C \in \prod_i \bar{C^i}$. that is, a cluster contains a (possibly empty)
pcluster for every sequence in the database.
We shall denote by $\bar{C} = \{ C : C \in \prod_i \bar{C^i} \}$ 
the set of all Clusters.
\end{cluster}

We would like to associate Clusters with Scores.
A score system is be a mapping of Clusters to classifications.
A score function is a mapping of classifications to scores.
Formally:

\newcommand{\tpfn}{\left(\begin{smallmatrix} T_p & T_n & F_p & F_n \end{smallmatrix}\right)}

\begin{score} 
\mbox{}
\begin{itemize}
\item []A \emph{score system} is a mapping $\psi:\bar{C} \to \tpfn$
\item []A \emph{score function} is a mapping $\pi:\tpfn \to \Re$
\end{itemize}
Where 
\begin{align*}
T_p & = \text{True Positives}  &  & = \text{number of correct positive classifications} \\
T_n & = \text{True Negatives}  &  & = \text{number if correct negative classifications} \\
F_p & = \text{False Positives} &  & = \text{number of incorrect positive classifications}	\\
F_n & = \text{False Negatives} &  & = \text{number of incorrect negative classifications}	
\end{align*}
\end{score}

We can now define the two score functions which SeedSearcher employs:

\section{Score functions}
\subsection{Hyper-Geometric scoring function} \mbox {} \\
We define the \emph{Hyper Geometric Pvalue} $P_{hg}$ to be:
\begin{equation}
	P_{hg}\tpfn = \sum_{x \geq k} D_{hg} \left(\begin{smallmatrix} x & n & K & N \end{smallmatrix}\right)
\end{equation}		
Where \begin{equation}
			\left(\begin{smallmatrix} x \\ n \\ K \\ N \end{smallmatrix}\right) = 
			\left(\begin{smallmatrix} 	T_p & & & \\ 
												T_p & + F_p & & \\ 
												T_p & + F_n & & \\ 
												T_p & + F_p & + T_n & + F_n 
					\end{smallmatrix}\right) 
		\end{equation} 
and $D_{hg}$ is the hyper-geometric distribution:
\begin{equation}
D_{hg}(x, k, K, N) = 
\frac{%
	\left( \begin{array}{c} K \\ x \end{array} \right)%
	\left( \begin{array}{c} N-K \\ n-x \end{array} \right)%
}{%
	\left( \begin{array}{c} N \\ n \end{array} \right)%
}
\end{equation}		
Thus $P_{hg}$ is a pvalue and equals the sum of the tail of the hyper-geometric distribution. \\
The distribution $D_{hg}$ is more easily understood using the following scenario:
Let there be an urn with $N$ balls, $K$ of which are \emph{red}
and suppose we draw $n$ balls from the urn, $x$ of those are red.
then $H(x, n, K, N)$ is the chance to draw $n$ balls and that
\emph{at least} $x$ of these will be red.

\begin {loghyge}
Naturally, values of $P_{hg}$ are numbers $\in [0, 1]$ and can be very close to $0$.
So for both numerical stability and ease of use we shall define and use:
\begin{equation}
h\tpfn = -\log_{10} Pval_{hg}\tpfn
\end{equation}
\newline
This h shall be called the \emph{hyper-geometric scoring} function 
\end{loghyge}


\subsection{Exploss scoring function} \mbox {} \\
This is a much simpler score function, 
which only  ``rewards'' (or ``punishes'') according to correct (or incorrect) positive classifications:
The score is increased when a correct positive classification is made ($T_p$), 
and is decreased when an incorrect positive classification is made ($F_p$).
negative classifications are ignored ($T_n$, $F_n$).
This is still a discriminative function because it relies on classifications 
of both the positive and negative sets, unlike non-discriminate
functions which will rely only on classifications of the positive set, e.g. $T_p$ and $F_n$.

\begin{exploss} \mbox {} \\
Let $1 < \alpha,\beta$ be any fixed constansts. 
we define the exploss function $E$ to be:
\begin{equation}
E_{\alpha,\beta} (T_p, F_p) = \frac {\beta^{F_p}}{\alpha^{T_p}}
\end{equation}
\newline
This function receives values $\in (0, \infty)$ and it is easily seen
that the better the positive classification, the closer the score is to $0$.
so we again take:
\begin{equation}
e_{\alpha,\beta} (T_p, T_n, F_p, F_n) = -\log_{10} Exploss_{\alpha,\beta} (T_p, F_p)
\end{equation}
\newline
This $e$ shall be called the \emph{exploss scoring} function 
\end{exploss}

\section{Score systems}

We shall now recall the definitions in section 1, and define several ways to
map Clusters to $\tpfn$ classifications.
We shall assume to have a constant database of size N, with 
weights $W^i\in[0,1]$ on the sequences $s^i \quad i=1...N$ and also 
positional weights $W^i_j \in [0,1]$ on any position in any sequence.

\begin {scoreremark}
In the simplest case, the prior on the regulation of $s^i$ is discrete, 
and there is no positional weight prior. thus: 
\begin{equation*}
	\forall i \quad W^i =	\begin{cases}
										1 & \text{if The sequence $s^i$ is positively labeled } \\
										0 & \text{if The sequence $s^i$ is negatively labeled } 
									\end{cases} 
\end{equation*}
and 
\begin{equation*}
	\forall i \forall j \quad W^i_j = 1
\end{equation*}
\end{scoreremark}
To gain some intuition, let us retreat from the abstract and
focus our attention on the specific problem which we are trying to solve.
We are trying to find a motif (short IUPAC sequence) which will correctly separate
a database of gene promoters (sequences) into regulated (positively labeled)
and non-regulated (negatively labeled) sets, which are known in advance.
Now suppose we have such a motif $m$ of length $l$.
$m$ infers a Cluster $c$ which contains all the positions
in the promoters where $m$ starts.
we are interested in defining several $\rho$ classification functions such that: 
\begin{equation*}
	\rho (c) = \begin{pmatrix}
						T^{\rho}_p (c) \\
						T^{\rho}_n (c) \\
						F^{\rho}_p (c) \\
						F^{\rho}_n (c)
					\end{pmatrix} 
				= \sum_i \rho_i(c^i) 
				= \sum_i \begin{pmatrix}
								 T^{\rho_i}_p (c^i) \\
								 T^{\rho_i}_n (c^i) \\
								 F^{\rho_i}_p (c^i) \\
								 F^{\rho_i}_n (c^i) \\
								\end{pmatrix}
\end{equation*}		
Thus a classification of a Cluster $c$ is the sum of the classifications on $c^i$ PClusters.
How do we classify a PCluster? there are a couple of questions involved, with several good answers:
\begin{itemize}
	\item 	\emph{$\omega$ pweight functions:}
				how much does a position $p^i_j$ (the j-th coordinate of sequence i) weigh? 
				we can define several different weight functions on positions. we call these
				pweight functions, and they are denoted with the letter $\omega$
				\begin{itemize}
				\item		\emph{Discrete pweight}: given a threshold $t$ (usually $t = 0.5$) 
							we define the $\omega^t_d$ discrete pweight function with threshold $t$ function to be:
							\begin{equation*}
								\omega^t_d (p^i_j) = \begin{cases}
																1 & \text{if $t < W^i$ (The sequence is positively labeled) } \\
																0 & \text{if $W^i <= t$ (The sequence is negatively labeled) } 
															\end{cases}
							\end{equation*}		
		\item		We define the \emph{real pweight} $\omega_r$ function to be:
					\begin{equation*}
						\omega_r (p^i_j) = W^i
					\end{equation*}			
					Using this function a position weighs the same as the sequence it belongs to.
		\item 	We define the positional pweight $\omega_p$ function to be: 
					\begin{equation*}
						\omega_p (p^i_j) = W^i \cdot W^i_j
					\end{equation*}
					Using this function the prior on the coordinates is taken into account.
		\end{itemize}
	\item 	\emph{$\rho$ pcluster classification functions:}
				How do we handle several classifications of same the same sequence?
				that is, how do we classify a $c^i$ cluster which contains
				several positions $p^i_{j_1}, ..., p^i_{j_n}$ all belonging to the same sequence $s^i$?
				given some pweight function $\omega$ we can define several 
				$\rho_{\omega}$ \emph{pcluster classification} functions:
				\begin{itemize}
					\item	We define the \emph{$\rho^1$ single position classification} function to be: 
						\begin{equation*}
							\rho^1_{\omega} (c^i) =	\begin{pmatrix}
																\displaystyle \max_{p^i_j \in c^i} \{\omega (p^i_j) \} \\
																\displaystyle 1 - \max_{p^i_j \in c^i} \{\omega (p^i_j) \}
															\end{pmatrix}
						\end{equation*}
						Using this function only the ``best'' position in each pcluster is taken into accout.
					\item	We define the \emph{$\rho^{\infty}$ total positions classification} function to be: 
					\begin{equation*}						
						\rho^{\infty}_{\omega} (c^i) =
						\begin{pmatrix}
							\displaystyle \sum_{p^i_j \in c^i} \omega (p^i_j) \\
							\displaystyle \sum_{p^i_j \in c^i} 1 - \omega (p^i_j)
						\end{pmatrix}
					\end{equation*}
					Using this function all the positions of a pcluster are taken into account.
				\end{itemize}	
\end{itemize}
Let $\omega$ be a pweight function $\in \{ \omega^t_d , \omega_r , \omega_p \}$ \\
and let $\rho$ be a counting function $\in \{ \rho^1_{\omega} , \rho^{\infty}_{\omega} \}$.
We shall define the \emph{score system $\rho$} to be
\begin{equation*}
	\begin{pmatrix} 
		T_p^{\rho}(c) \\ 
		F_p^{\rho}(c) 
	\end{pmatrix} = 
	\sum_i	\begin{pmatrix} 
		T_p^{\rho}(c^i) \\ 
		F_p^{\rho}(c^i) 
	\end{pmatrix} = 
	\sum_i \rho(c^i) \\
\end{equation*}
\begin{align*}
		\begin{pmatrix} 
			F_n^{\rho}(c) \\ 
			T_n^{\rho}(c) 
		\end{pmatrix}  
		& =	\sum_i \begin{pmatrix} 
					F_n^{\rho}(c^i) \\ 
					T_n^{\rho}(c^i) 
				\end{pmatrix} \\
		& = \sum_i 	\left( \rho(s^i) - 	\rho(c^i) \right) \\
		& = \sum_i	\left( \rho(s^i) -	\begin{pmatrix} 
														T_p^{\rho}(c^i) \\ 
														F_p^{\rho}(c^i) 
													\end{pmatrix} 
						\right) \\
		& = \left(	\sum_i  \rho(s^i) \right) -	\begin{pmatrix} 
																	T_p^{\rho}(c) \\ 
																	F_p^{\rho}(c) 
																\end{pmatrix}
\end{align*}
We have successfully defined several scoring systems, which map clusters into $\tpfn$ classifications.
Summing up our method: we classify each pcluster using either the ``best'' position in the cluster (single position classification) 
or using all the positions in the cluster (total positions classification).
each position is weighed using a discrete/real/positional weight function.
this system maps a motif (with its corresponding cluster) to a $\tpfn$ classification of the database.
We use either an exploss or hyper-geometrical score function to map these classification vectors
into real-valued scores.

\section{remarks}
Several issues still need further refining:

\subsection{removing overlaps in total position classifications}
When pclusters reflect the starting positions of a motif $m$ with length $l$
it often make sense not to allow overlaping positions.
position $p^i_j$ overlaps with $p^i_k$ iff (assuming $w.l.g \quad j<k$) $k \in [j, j + l)$.
Thus $\rho(s^i)$ now stands for a classification of the maximum overlap-free set of positions in $s^i$.

\subsection{DNA sequences: using the reverse strand}
When the sequences in concern are DNA, it often makes sense to ``look'' for motifs
in both the positive and reverse strands. This affects scoring in a simple way:
The reverse strands are not added as sequences, 
but rather they have the effect of doubling the length of all sequences.
However, when a cluster $c^i$ (or even $s^i$ for that matter) is cleaned off overlaps
the overlaps are removed separately from the positive and reverse strands.

\subsection{future changes}
The positional pweight function will change to reflect the positional bias
along the entire motif (and not just the starting position)
\end{document}
